# -*- coding: utf-8 -*-
"""deep_learning_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q6yAbjwBuK69WQv9w16YbH4BhyLJN7Wu
"""

# imports for the tutorial
import numpy as np
import matplotlib.pyplot as plt
import time
import os
import glob

# pytorch
import torch
import torch.nn as nn
import torchvision
from torchvision import models, transforms, datasets
from torch.utils.data import DataLoader, Dataset, random_split
import torch.nn.functional as F
import json
from PIL import Image

from torch.amp import autocast, GradScaler
import argparse
import re

import kornia.augmentation as K
import seaborn as sns
from sklearn.metrics import confusion_matrix
import torchvision.models as models


DATA_ROOT_DIR = "/home/projects/sipl-prj10219/Nufar_Ori"
CHECK_POINT_DIR = f"/home/projects/sipl-prj10219/Nufar_Ori/checkpoints"
# Standard ImageNet statistics as requested
IMAGENET_MEAN = [0.485, 0.456, 0.406]
IMAGENET_STD = [0.229, 0.224, 0.225]

class ResNet(nn.Module):
    def __init__(self, num_classes=100, model_size=50):
        super().__init__()

        # torchvision ResNet
        if model_size == 50:
            self.backbone = models.resnet50(weights=None)
        elif model_size == 18:
            self.backbone = models.resnet18(weights=None)
        else:  # raise error
            raise ValueError("Invalid model size.")
        self.num_classes = num_classes
        self.feature_dim = self.backbone.fc.in_features
        # remove classifier from backbone
        self.backbone.fc = nn.Identity()
        # our fc layer after resnet CNN
        self.fc = nn.Linear(self.feature_dim, num_classes)

    def forward(self, x):
        features = self.backbone(x)  # (N, 2048)
        logits = self.fc(features)  # (N, num_classes)
        return logits, features


class CECosineReg(nn.Module):
    def __init__(self, reg_weight=0.1):
        """
        weight: The lambda coefficient for the regularization term.
        """
        super(CECosineReg, self).__init__()
        self.ce = nn.CrossEntropyLoss(label_smoothing=0.1)
        self.reg_weight = reg_weight

    def forward(self, logits, targets, features):
        # Standard Cross Entropy Loss
        ce_loss = self.ce(logits, targets)

        # Cosine Similarity Regularization (forcing orthogonality)
        # Normalize features to unit length for cosine calculation
        features_norm = F.normalize(features, p=2, dim=1)

        # Calculate the Gram Matrix (N x N) of cosine similarities between all samples
        sim_matrix = torch.mm(features_norm, features_norm.t())

        # We want to force orthogonality for i != j, meaning similarity should be 0.
        # Create a mask to ignore the diagonal (self-similarity which is always 1)
        n = sim_matrix.size(0)
        mask = torch.eye(n).to(features.device)
        off_diag_sim = sim_matrix * (1 - mask)

        # Penalize non-zero similarities (squared to penalize both + and - correlation)
        cosine_loss = (off_diag_sim**2).sum() / (n * (n - 1))

        # Total Loss
        return ce_loss + (self.reg_weight * cosine_loss), self.reg_weight * cosine_loss


def SIGReg(x, global_step, num_slices=256):
    """
    Sketched Isotropic Gaussian Regularization (SIGReg).
    x: (Batch, Features) tensor from the last CNN layer.
    global_step: Current training iteration (used for seeding projections).
    """
    dev = x.device

    # Slice Sampling: Generate random unit-norm directions
    # Using a seed based on global_step ensures variety across steps
    g = torch.Generator(device=dev)
    g.manual_seed(global_step)
    proj_shape = (x.size(1), num_slices)
    A = torch.randn(proj_shape, generator=g, device=dev)
    A = A / A.norm(p=2, dim=0)  # Normalize to unit vectors

    # Project features onto these directions
    # (N, K) @ (K, M) -> (N, M)
    z = torch.mm(x, A)

    # Epps-Pulley Statistic: Match to Target Gaussian N(0,1)
    # Use 17 quadrature points in the [-5, 5] domain as recommended in paper
    t = torch.linspace(-5, 5, 17, device=dev)
    exp_f = torch.exp(-0.5 * t**2)  # Theoretical CF for N(0,1)

    # Compute Empirical Characteristic Function (ECF)
    # x_t shape: (Batch, Slices, T_points)
    x_t = z.unsqueeze(2) * t.view(1, 1, -1)

    # Real and imaginary parts of the characterictics func exp(i * t * z)
    phi_real = torch.cos(x_t).mean(0)  # (Slices, T_points)
    phi_imag = torch.sin(x_t).mean(0)

    # Calculate Weighted L2 distance
    # |phi_empirical - phi_target|^2 * weight_window
    err = ((phi_real - exp_f).pow(2) + phi_imag.pow(2)) * exp_f

    # Integrate using trapezoidal rule
    N = x.size(0)
    T = torch.trapezoid(err, t, dim=1) * N

    return T.mean()  # Average across all directions (slices)


class CESIGReg(nn.Module):
    def __init__(self, reg_weight=0.05):
        """
        reg_weight: Weight for the SIGReg term. Paper recommends 0.05.
        """
        super(CESIGReg, self).__init__()
        self.ce = nn.CrossEntropyLoss(label_smoothing=0.1)
        self.reg_weight = reg_weight
        self.iteration = 0  # To track global_step internally

    def forward(self, logits, targets, features):
        ce_loss = self.ce(logits, targets)

        # Isotropic Gaussian Regularization
        sigreg_loss = SIGReg(features, self.iteration)

        self.iteration += 1

        return ce_loss + self.reg_weight * sigreg_loss, self.reg_weight * sigreg_loss


class CEVICReg(nn.Module):
    def __init__(
        self,
        reg_weight=1.0,
        inv_coeff=25.0,
        std_coeff=25.0,
        cov_coeff=1.0,
        gamma=1.0,
        epsilon=1e-4,
    ):
        """
        VICReg Regularization with Cross Entropy for Supervised Learning.

        Args:
            reg_weight: Global lambda to scale the total VICReg contribution.
            std_coeff: Internal VICReg weight for the variance term (default 25.0).
            cov_coeff: Internal VICReg weight for the covariance term (default 1.0).
            gamma: Target value for the standard deviation (fixed to 1 in the paper).
            epsilon: Small scalar for numerical stability (1e-4).
        """
        super(CEVICReg, self).__init__()
        self.ce = nn.CrossEntropyLoss(label_smoothing=0.1)
        self.reg_weight = reg_weight
        self.std_coeff = std_coeff
        self.cov_coeff = cov_coeff
        self.gamma = gamma
        self.epsilon = epsilon
        self.inv_coeff = inv_coeff

    def forward(self, logits_a, logits_b, features_a, features_b, targets):
        """
        Args:
            logits: Output from the FC layer (for CE loss).
            features: Output from the last CNN layer (for VICReg regularization).
            targets: Ground truth labels.
        """
        # Standard Cross Entropy Loss
        # ce_loss = self.ce(logits_a, targets) + self.ce(logits_b, targets)
        ce_loss = self.ce(logits_a, targets)

        # VICReg Single-Batch Regularization
        # Z represents the batch of embeddings/features
        total_var_loss = 0
        total_cov_loss = 0

        for z in [features_a, features_b]:
            n, d = z.shape

            # --- Variance Term ---
            # Calculate regularized standard deviation along the batch dimension
            std_z = torch.sqrt(z.var(dim=0) + self.epsilon)
            # Hinge loss to maintain variance above threshold gamma
            total_var_loss += torch.mean(F.relu(self.gamma - std_z))

            # --- Covariance Term ---
            # Center the features along the batch dimension
            z_norm = z - z.mean(dim=0)
            # Compute the covariance matrix (d x d)
            cov_z = (z_norm.T @ z_norm) / (n - 1)
            # Sum of squared off-diagonal coefficients to decorrelate dimensions
            mask = 1 - torch.eye(d).to(z.device)
            off_diag_cov = cov_z * mask
            total_cov_loss += off_diag_cov.pow(2).sum() / d

        invariance_loss = F.mse_loss(features_a, features_b)

        # Weighted Regularization
        # Combined VICReg components as defined in the paper
        vicreg_loss = (
            (self.std_coeff * total_var_loss)
            + (self.cov_coeff * total_cov_loss)
            + (self.inv_coeff * invariance_loss)
        )

        weigthed_loss = self.reg_weight * vicreg_loss

        return ce_loss + weigthed_loss, weigthed_loss


def build_imagenet_metadata(root):
    # Load the raw labels from JSON
    labels_json_path = os.path.join(root, "Labels.json")
    with open(labels_json_path, "r") as f:
        id_to_name_raw = json.load(f)

    def clean_name(name):
        return name.split(",")[0].strip().title()

    # Scan all possible folders to find every unique class ID (folder name)
    all_parent_folders = ["train.X1", "train.X2", "train.X3", "train.X4", "val.X"]
    unique_class_ids = set()

    for folder in all_parent_folders:
        folder_path = os.path.join(root, folder)
        if os.path.exists(folder_path):
            classes = [
                d
                for d in os.listdir(folder_path)
                if os.path.isdir(os.path.join(folder_path, d))
            ]
            unique_class_ids.update(classes)

    # Sort IDs to ensure the integer mapping is deterministic
    sorted_class_ids = sorted(list(unique_class_ids))

    # Create the shared mappings
    class_to_idx = {cls_id: i for i, cls_id in enumerate(sorted_class_ids)}
    idx_to_human_name = {
        i: clean_name(id_to_name_raw.get(cls_id, cls_id))
        for i, cls_id in enumerate(sorted_class_ids)
    }

    return class_to_idx, idx_to_human_name


class ImageNet100Dataset(Dataset):
    def __init__(
        self,
        root,
        split="train",
        transform=None,
        class_to_idx=None,
        idx_to_human_name=None,
    ):
        self.transform = transform
        self.samples = []
        self.class_to_idx = class_to_idx
        self.idx_to_human_name = idx_to_human_name

        # Determine which folders to scan for files
        folders = (
            ["train.X1", "train.X2", "train.X3", "train.X4"]
            if split == "train"
            else ["val.X"]
        )

        for folder in folders:
            folder_path = os.path.join(root, folder)
            if not os.path.exists(folder_path):
                continue

            for class_name in os.listdir(folder_path):
                class_folder = os.path.join(folder_path, class_name)
                if (
                    not os.path.isdir(class_folder)
                    or class_name not in self.class_to_idx
                ):
                    continue

                label = self.class_to_idx[class_name]
                for img_file in os.listdir(class_folder):
                    img_path = os.path.join(class_folder, img_file)
                    self.samples.append((img_path, label))

    def view_images(self, num_images: int, loader: DataLoader) -> None:
        """
        View a grid of images from this dataset.

        Args:
            num_images: Total number of images to show (must be divisible by 5)
            loader: DataLoader wrapping this dataset
        """
        images, targets = next(iter(loader))

        plt.figure(figsize=(15, 10))
        assert num_images % 5 == 0, "num_images must be divisible by 5"

        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)
        std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)

        for i in range(num_images):
            img = images[i]
            label = targets[i].item()

            # denormalize
            img = img * std + mean
            img = img.clamp(0, 1)  # avoid display artifacts

            plt.subplot(num_images // 5, 5, i + 1)
            plt.title(f"{self.idx_to_human_name[label]}", fontdict={"size": 7})
            plt.imshow(img.permute(1, 2, 0))  # C,H,W â†’ H,W,C
            plt.axis("off")

        plt.tight_layout()
        plt.show()

    def __getitem__(self, idx):
        path, label = self.samples[idx]
        image = Image.open(path).convert("RGB")
        if self.transform:
            image = self.transform(image)
        return image, label

    def __len__(self):
        return len(self.samples)


def get_augmentation_pipeline():
    aug_pipeline = K.AugmentationSequential(
        K.ColorJiggle(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1, p=0.5),
        # Random crop with reflection padding
        K.RandomCrop((224, 224)),
        # Random horizontal flip
        K.RandomHorizontalFlip(p=0.5),
        K.RandomGrayscale(p=0.1),
        # Mild Gaussian blur
        K.RandomGaussianBlur(kernel_size=(9, 9), sigma=(0.1, 2.0), p=0.3),
        K.RandomSolarize(p=0.1),
        data_keys=["input"],
    )
    return aug_pipeline


def calculate_accuracy(model, dataloader, num_classes, device):
    model.eval()
    total_correct = 0
    total_images = 0
    # Use 100 or dynamic length based on dataset
    confusion_matrix = np.zeros([num_classes, num_classes], int)

    with torch.no_grad():
        for images, labels in dataloader:
            images, labels = images.to(device), labels.to(device)
            if isinstance(model, ResNet):
                outputs, _ = model(images)  # forward pass
            else:
                outputs = model(images)  # forward pass
            _, predicted = torch.max(outputs, 1)

            total_images += labels.size(0)
            total_correct += (predicted == labels).sum().item()

            # Update confusion matrix for EVERY batch
            for i in range(labels.size(0)):
                confusion_matrix[labels[i].item(), predicted[i].item()] += 1

    model_accuracy = (total_correct / total_images) * 100
    return model_accuracy, confusion_matrix


def get_latest_checkpoint(checkpoint_dir, loss_name, reg_weight=None, max_epoch=None):
    """
    Maps the loss_name (and optional reg_weight) to the specific .pth file path  by finding the highest epoch.
    """
    if reg_weight is not None:
        # strict pattern for hyperparam tuning
        pattern = os.path.join(
            checkpoint_dir,
            f"checkpoint_{loss_name}_epoch_*_reg_weight_{reg_weight}.pth",
        )
    else:
        # Standard pattern
        pattern = os.path.join(checkpoint_dir, f"checkpoint_{loss_name}_epoch_*.pth")
    checkpoint_files = glob.glob(pattern)

    if not checkpoint_files:
        # If we looked for a specific weight and failed, we might want to log that specifically
        if reg_weight is not None:
            print(
                f"No checkpoint found for {loss_name} with reg_weight={reg_weight} in {checkpoint_dir}"
            )
        else:
            print(f"No checkpoint found for {loss_name} in {checkpoint_dir}")
        return None

    # If max_epoch is set, keep only files where epoch <= max_epoch
    if max_epoch is not None:
        checkpoint_files = [
            x
            for x in checkpoint_files
            if int(re.search(rf"checkpoint_{loss_name}_epoch_(\d+).*\.pth", x).group(1))
            <= max_epoch
        ]

        # If the filter removed all files
        if not checkpoint_files:
            print(f"No checkpoint found for {loss_name} with epoch <= {max_epoch}")
            return None
    # Sort by epoch number found in filename using regex
    checkpoint_files.sort(
        key=lambda x: int(
            re.search(rf"checkpoint_{loss_name}_epoch_(\d+).*\.pth", x).group(1)
        )
    )
    latest_checkpoint = checkpoint_files[-1]
    return latest_checkpoint


def get_imagenet_dataloaders(batch_size=128, num_workers=4, use_full_train_set=False):
    """
    Encapsulates the data loading logic from the main project file.
    """
    # Define transforms matching your project requirements
    train_transform = transforms.Compose(
        [
            transforms.Resize((256, 256)),
            transforms.ToTensor(),
            transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),
        ]
    )

    val_transform = transforms.Compose(
        [
            transforms.Resize((256, 256)),
            transforms.ToTensor(),
            transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),
        ]
    )

    # Note: Requires shared_class_to_idx and shared_idx_to_human to be accessible or generated
    shared_class_to_idx, shared_idx_to_human = build_imagenet_metadata(DATA_ROOT_DIR)

    full_train_set = ImageNet100Dataset(
        root=DATA_ROOT_DIR,
        split="train",
        transform=train_transform,
        class_to_idx=shared_class_to_idx,
        idx_to_human_name=shared_idx_to_human,
    )

    test_dataset = ImageNet100Dataset(
        root=DATA_ROOT_DIR,
        split="val",
        transform=val_transform,
        class_to_idx=shared_class_to_idx,
        idx_to_human_name=shared_idx_to_human,
    )

    if use_full_train_set:
        print("Mode: Full Train Set (No Validation Split)")
        # Use the whole dataset for training
        train_dataset = full_train_set
        val_loader = None
    else:
        # Standard Split logic
        train_size = int(0.8 * len(full_train_set))
        val_size = len(full_train_set) - train_size

        gen = torch.Generator().manual_seed(42)
        train_dataset, val_dataset = random_split(
            full_train_set, [train_size, val_size], generator=gen
        )

        val_loader = DataLoader(
            val_dataset,
            batch_size=batch_size,
            shuffle=False,
            num_workers=num_workers,
            pin_memory=True,
        )

    # Create loaders(train_dataset is either the subset or the full set depending on the use_full_train_set
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=True,
    )
    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True,
    )

    return train_loader, val_loader, test_loader, full_train_set, test_dataset


def train_and_evaluate_cnn(
    model,
    device,
    loss_criterion,
    train_loader,
    val_loader,
    test_loader,
    optimizer,
    scheduler,
    loss_name,
    num_classes,
    epochs=10,
    augmentation_pipeline=None,
    checkpoint_dir="",
    is_hyperparam_tuning=False,
    reg_weight=None,
):
    print(f"running with loss {loss_name}")
    use_cuda = device.type == "cuda"
    print(f"Using {device.type}, use_cuda={use_cuda}")
    scaler = GradScaler(enabled=use_cuda)

    train_losses, train_accs, val_accs = [], [], []
    start_epoch = 1

    # Load the latest checkpoint if it exists
    if not os.path.isdir(checkpoint_dir):
        os.mkdir(checkpoint_dir)

    latest_checkpoint = get_latest_checkpoint(
        checkpoint_dir, loss_name, reg_weight, epochs
    )

    if latest_checkpoint:
        print(f"Loading latest checkpoint: {latest_checkpoint}")
        checkpoint = torch.load(latest_checkpoint, map_location=device)

        # Restore states
        model.load_state_dict(checkpoint["model_state_dict"])
        optimizer.load_state_dict(checkpoint["optimizer_state_dict"])
        if scheduler and "scheduler_state_dict" in checkpoint:
            scheduler.load_state_dict(checkpoint["scheduler_state_dict"])

        # Restore history and epoch
        start_epoch = checkpoint["epoch"] + 1
        train_losses = checkpoint.get("train_losses", [])
        train_accs = checkpoint.get("train_accs", [])
        val_accs = checkpoint.get("val_accs", [])
        if not val_accs:
            print("No validation data found (Full Train Set mode)")

        print(f"Resuming training from epoch {start_epoch}")
    else:
        print("Starting from scratch.")

    for epoch in range(start_epoch, epochs + 1):
        model.train()
        epoch_time = time.time()
        running_loss, regularization_running_loss, total_train, correct_train = (
            0.0,
            0,
            0,
            0,
        )
        for i, data in enumerate(train_loader, 0):
            # get the inputs
            inputs, labels = data
            # send them to device
            inputs = inputs.to(device)
            labels = labels.to(device)
            # augmentation with `kornia` happens here inputs = aug_list(inputs)
            # forward + backward + optimize
            if augmentation_pipeline is not None:
                inputs = augmentation_pipeline(inputs)
                inputs_b = augmentation_pipeline(inputs)

            optimizer.zero_grad()  # zero the parameter gradients

            with autocast(device_type=device.type, enabled=use_cuda):
                if isinstance(model, ResNet):
                    outputs, cnn_features = model(inputs)  # forward pass
                else:
                    outputs = model(inputs)  # forward pass
                    cnn_features = None
                if loss_name == "Cross_Entropy":
                    loss = loss_criterion(outputs, labels)
                elif loss_name == "CE_With_VICReg":
                    outputs_b, cnn_features_b = model(inputs_b)  # forward pass
                    loss, regularization_loss = loss_criterion(
                        outputs, outputs_b, cnn_features, cnn_features_b, labels
                    )
                else:
                    # For Cosine Similarity, Isotropic Gaussian, or VICReg
                    # regularization_loss will include the Reg weight
                    loss, regularization_loss = loss_criterion(
                        outputs, labels, cnn_features
                    )

            _, predicted = outputs.max(1)
            total_train += labels.size(0)
            correct_train += predicted.eq(labels).sum().item()

            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

            running_loss += loss.data.item()
            if loss_name != "Cross_Entropy":
                regularization_running_loss += regularization_loss.data.item()

        avg_train_loss = running_loss / len(train_loader)
        current_train_acc = 100.0 * correct_train / total_train

        train_losses.append(avg_train_loss)
        train_accs.append(current_train_acc)

        if val_loader is not None:
            val_accuracy, _ = calculate_accuracy(model, val_loader, num_classes, device)
            val_accs.append(val_accuracy)
            val_log_str = "{:.3f}%".format(val_accuracy)
        else:
            # If full train set, we skip validation
            val_accuracy = 0.0
            val_log_str = "N/A"

        scheduler.step()
        log = "Epoch: {} | Loss: {:.4f} | Regularization Loss: {:.4f}  | Training accuracy: {:.3f}% | Val accuracy: {}% | ".format(
            epoch,
            running_loss,
            regularization_running_loss,
            current_train_acc,
            val_log_str,
        )
        epoch_time = time.time() - epoch_time
        log += "Epoch Time: {:.2f} secs".format(epoch_time)
        print(log)

        # save model
        if epoch % 5 == 0:
            print("==> Saving model ...")

            save_filename = f"checkpoint_{loss_name}_epoch_{epoch}.pth"
            if reg_weight is not None:
                save_filename = (
                    save_filename[:-4] + "_reg_weight_" + str(reg_weight) + ".pth"
                )
            save_path = os.path.join(checkpoint_dir, save_filename)

            torch.save(
                {
                    "epoch": epoch,
                    "model_state_dict": model.state_dict(),
                    "optimizer_state_dict": optimizer.state_dict(),
                    "scheduler_state_dict": (
                        scheduler.state_dict() if scheduler else None
                    ),
                    "train_losses": train_losses,
                    "train_accs": train_accs,
                    "val_accs": val_accs,
                },
                save_path,
            )
            print(f"Checkpoint saved at {save_path}")
    
    print("==> Finished Training ...")
    fig, ax1 = plt.subplots(figsize=(8, 4))

    # Plot 1: Loss (Left Axis)
    p1 = ax1.plot(train_losses, "b-o", label="Train Loss")
    ax1.set_xlabel("Epoch")
    ax1.set_ylabel("Train Loss", color="b")
    ax1.tick_params(axis="y", labelcolor="b")

    # Plot 2 & 3: Accuracies (Right Axis)
    ax2 = ax1.twinx()  # Create shared axis for accuracies

    # Plot Train Accuracy (Green Triangles)
    p3 = ax2.plot(train_accs, "g-^", label="Train Accuracy")

    ax2.set_ylabel("Accuracy (%)", color="k")

    # Plot Val Accuracy ONLY if it exists
    if len(val_accs) > 0:
        p2 = ax2.plot(val_accs, "r-s", label="Val Accuracy")
        lines = p1 + p2 + p3
    else:
        lines = p1 + p3

    labels = [l.get_label() for l in lines]
    ax1.legend(
        lines, labels, loc="center right"
    )

    plt.title(f"Train and Val accuracy, Loss For Metric: {loss_name}")
    plt.tight_layout()
    if reg_weight is not None:
        base_path = os.path.join(checkpoint_dir, f"{loss_name}_regularization_weight_{reg_weight}")
    else:
        base_path = os.path.join(checkpoint_dir, f"{loss_name}")
    loss_plot_path = base_path + "_plot.png"
    plt.savefig(loss_plot_path)
    print(f"Saved metrics plot to: {loss_plot_path}")
    plt.show()
    plt.close()

    if test_loader is not None:
        print(f"\n--- Final Evaluation on Test Set ---")
        model.eval()  # Ensure model is in eval mode
        test_accuracy, confusion_mat = calculate_accuracy(
            model, test_loader, num_classes, device
        )
        print(f"Final Test Accuracy: {test_accuracy:.2f}%")
        # Plot Confusion Matrix
        plt.figure(figsize=(12, 10))
        sns.heatmap(
            confusion_mat, annot=False, cmap="Blues"
        )  # annot=False if classes > 20
        plt.title(f"Confusion Matrix: {loss_name}")
        plt.xlabel("Predicted Label")
        plt.ylabel("True Label")
        confusion_mat_path = base_path + "_confusion_matrix.png"
        print(f"Saved confusion matrix to: {confusion_mat_path}")
        plt.savefig(confusion_mat_path)
        test_accuracy_path = base_path + "_test_accuracy.pth"
        torch.save({"test_accuracy": test_accuracy}, test_accuracy_path)
        plt.show()
        plt.close()


def get_dataset_classes(name):
    mapping = {
        "cifar10": 10,
        "imagenet100": 100,
        "flowers102": 102,
        "eurosat": 10,
        "pcam": 2,
        "dtd": 47,
    }
    return mapping.get(name)


class TargetModel:
    def __init__(self, dataset_name, loss_name, checkpoint_dir, reg_weight=None):
        self.dataset_name = dataset_name.lower()
        self.loss_name = loss_name  # Keep original casing if needed for file patterns
        self.checkpoint_dir = checkpoint_dir
        self.reg_weight = reg_weight
        # Resolve latest checkpoint path
        self.checkpoint_path = get_latest_checkpoint(
            self.checkpoint_dir, self.loss_name, self.reg_weight
        )

        # Map dataset to number of classes
        self.new_num_classes = get_dataset_classes(self.dataset_name)

        # Initialize original architecture (ImageNet100 = 100 classes)
        self.model = ResNet(num_classes=100, model_size=50)

        # Load the pre-trained weights
        if self.checkpoint_path:
            self._load_weights()
        else:
            print(
                "Warning: Model initialized with random weights because no checkpoint was found."
            )

        # Freeze all CNN backbone weights
        for param in self.model.parameters():
            param.requires_grad = False

        # Replace the FC layer (ResNet50 in_features = 2048)
        num_features = self.model.fc.in_features
        self.model.fc = nn.Linear(num_features, self.new_num_classes)

        # Set criterion to standard CrossEntropy (no regularization for transfer task)
        self.criterion = nn.CrossEntropyLoss()

    def _load_weights(self):
        """Loads weights from the inferred path into the model."""
        print(f"Loading weights from: {self.checkpoint_path}")
        checkpoint = torch.load(self.checkpoint_path, map_location="cpu")

        if "model_state_dict" in checkpoint:
            state_dict = checkpoint["model_state_dict"]
        elif "state_dict" in checkpoint:
            state_dict = checkpoint["state_dict"]
        else:
            state_dict = checkpoint

        self.model.load_state_dict(state_dict)
        print(f"Successfully loaded {self.loss_name} backbone.")

    def get_model(self):
        """Returns the prepared model and the CE criterion."""
        return self.model, self.criterion


def train_wrapper(
    dataset_name,
    loss_name,
    train_loader,
    val_loader,
    test_loader,
    checkpoint_dir,
    device,
    samples_per_class,
    epochs=10,
    should_train_from_scratch=False,
    reg_weight=None,
    transfer_learning_model_size=None
):
    """
    Runs transfer learning on a provided set of DataLoaders.
    """
    print(f"\n>>> Starting Experiment: {dataset_name} | Weights from: {loss_name}")

    # Initialize TargetModel
    # Automatically finds latest checkpoint and freezes the CNN backbone
    if should_train_from_scratch:
        if transfer_learning_model_size == 18:
            model = models.resnet18(
                weights=None, num_classes=get_dataset_classes(dataset_name)
            )
        elif transfer_learning_model_size == 50:
            model = models.resnet50(
                weights=None, num_classes=get_dataset_classes(dataset_name)
            )
        else:
            raise ValueError(f"Invalid model size: {transfer_learning_model_size} please use args to set this variable to 18 or 50.")
        trained_parameters = model.parameters()
        criterion = nn.CrossEntropyLoss()
    else:
        target_setup = TargetModel(
            dataset_name=dataset_name,
            loss_name=loss_name,
            checkpoint_dir=checkpoint_dir,
            reg_weight=reg_weight,
        )
        model, criterion = target_setup.get_model()
        trained_parameters = model.fc.parameters()
    model = model.to(device)

    optimizer = torch.optim.SGD(
        trained_parameters, lr=0.01, momentum=0.9, weight_decay=1e-4
    )

    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)

    transfer_learning_dir = os.path.join(checkpoint_dir, "transfer_results")
    if not os.path.isdir(transfer_learning_dir):
        os.mkdir(transfer_learning_dir)

    # Result directory for this specific experiment
    if should_train_from_scratch:
        experiment_results_dir = os.path.join(
            checkpoint_dir,
            "transfer_results",
            f"dataset_{dataset_name}_from_scratch_model_size_{transfer_learning_model_size}",
        )
    else:
        experiment_results_dir = os.path.join(
            checkpoint_dir,
            "transfer_results",
            f"dataset_{dataset_name}_from_loss_{loss_name}",
        )

    if samples_per_class != 0:
        experiment_results_dir += f"_trimming_to_{samples_per_class}"

    if reg_weight is not None:
        experiment_results_dir += f"_reg_weight_{reg_weight}"
    print_config(device, model, optimizer, scheduler, epochs, loss_name, None)
    train_and_evaluate_cnn(
        model=model,
        device=device,
        loss_criterion=criterion,
        train_loader=train_loader,
        val_loader=val_loader,
        test_loader=test_loader,
        optimizer=optimizer,
        scheduler=scheduler,
        loss_name="Cross_Entropy",  # Target task always uses standard CE
        num_classes=get_dataset_classes(dataset_name),
        epochs=epochs,
        checkpoint_dir=experiment_results_dir,
    )

    print(f">>> Finished Experiment: {dataset_name}_{loss_name}")

def get_trimmed_dataset(train_dataset, samples_per_class):
    """
    Robustly subsets a dataset, handling nested Subsets and raw Datasets (full train mode).
    """

    # Check if the dataset is a Subset (created by random_split)
    if isinstance(train_dataset, torch.utils.data.Subset):
        current_dataset = train_dataset.dataset
        current_indices = train_dataset.indices

        # Unpack nested subsets if necessary (e.g. EuroSAT logic)
        while isinstance(current_dataset, torch.utils.data.Subset):
            current_indices = [current_dataset.indices[i] for i in current_indices]
            current_dataset = current_dataset.dataset
        
        root_dataset = current_dataset
        root_indices = current_indices

    # If it is NOT a subset, it is the raw dataset (Full Train Mode)
    else:
        root_dataset = train_dataset
        root_indices = list(range(len(root_dataset)))

    # Extract Targets from the Root
    if hasattr(root_dataset, "targets"):
        all_targets = np.array(root_dataset.targets)
    elif hasattr(root_dataset, "labels"):
        all_targets = np.array(root_dataset.labels)
    elif hasattr(root_dataset, "_labels"):
        all_targets = np.array(root_dataset._labels)
    elif hasattr(root_dataset, "samples"):  # Catch-all for ImageFolder
        all_targets = np.array([s[1] for s in root_dataset.samples])
    else:
        # Final fallback
        try:
            all_targets = np.array([y for _, y in root_dataset])
        except Exception as e:
            raise AttributeError(f"Could not extract labels: {e}")

    #Filter and Trim 
    subset_targets = all_targets[root_indices]
    unique_classes = np.unique(subset_targets)
    final_indices = []

    for cls in unique_classes:
        cls_locs = np.where(subset_targets == cls)[0]

        if len(cls_locs) < samples_per_class:
            print(f"Warning: Class {cls} has only {len(cls_locs)} samples.")
            selected_locs = cls_locs
        else:
            rng = np.random.default_rng(seed=42)
            selected_locs = rng.choice(cls_locs, samples_per_class, replace=False)

        # Map back to absolute root indices
        absolute_indices = [root_indices[loc] for loc in selected_locs]
        final_indices.extend(absolute_indices)

    return torch.utils.data.Subset(root_dataset, final_indices)


def execute_transfer_learning(
    dataset_name,
    loss_name,
    checkpoint_dir,
    should_train_from_scratch,
    samples_per_class=0,
    epochs=10,
    reg_weight=None,
    is_hyperparam_tuning=False,
    use_full_train_set=False,
    transfer_learning_model_size=None
):
    """
    Orchestrates the data preparation (loading & trimming) and
    launches the transfer learning experiment.
    """
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # Define Standard ResNet Transforms
    transform = transforms.Compose(
        [
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ]
    )

    # Dataset Selector Logic
    ds_name = dataset_name.lower()

    if ds_name == "cifar10":
        full_train_set = torchvision.datasets.CIFAR10(
            root="./data", train=True, download=True, transform=transform
        )
        test_set = torchvision.datasets.CIFAR10(
            root="./data", train=False, download=True, transform=transform
        )

    elif ds_name == "flowers102":
        full_train_set = torchvision.datasets.Flowers102(
            root="./data", split="train", download=True, transform=transform
        )
        test_set = torchvision.datasets.Flowers102(
            root="./data", split="test", download=True, transform=transform
        )

    elif ds_name == "eurosat":
        # EuroSAT does not have a native 'split' argument in torchvision.
        full_dataset = torchvision.datasets.EuroSAT(
            root="./data", download=True, transform=transform
        )

        # We must manually split into training and a test set
        total_len = len(full_dataset)
        train_len = int(0.8 * total_len)
        test_len = total_len - train_len

        gen = torch.Generator().manual_seed(42)
        full_train_set, test_set = random_split(
            full_dataset, [train_len, test_len], generator=gen
        )

    elif ds_name == "dtd":
        full_train_set = torchvision.datasets.DTD(
            root="./data", split="train", download=True, transform=transform
        )
        test_set = torchvision.datasets.DTD(
            root="./data", split="test", download=True, transform=transform
        )

    else:
        raise ValueError(f"Dataset {dataset_name} not supported in this pipeline.")

    if use_full_train_set:
        print("!! Transfer Mode: Full Train Set (No Validation Split) !!")
        train_subset = full_train_set
        val_loader = None
    else:
        # Standard 80/20 split of the training set
        train_size = int(0.8 * len(full_train_set))
        val_size = len(full_train_set) - train_size
        gen = torch.Generator().manual_seed(42)
        train_subset, val_subset = random_split(
            full_train_set, [train_size, val_size], generator=gen
        )
        # Create val_loader here since it exists
        val_loader = DataLoader(val_subset, batch_size=32, shuffle=False, num_workers=2)

    # Ensures 'samples_per_class' images for each category in the training set
    if samples_per_class > 0:
        print(f"Trimming dataset to {samples_per_class} per class")
        train_subset = get_trimmed_dataset(train_subset, samples_per_class)

    # Create DataLoaders
    train_loader = DataLoader(train_subset, batch_size=32, shuffle=True, num_workers=2)
    test_loader = DataLoader(test_set, batch_size=32, shuffle=False, num_workers=2)

    train_wrapper(
        dataset_name=ds_name,
        loss_name=loss_name,
        train_loader=train_loader,
        val_loader=val_loader,
        test_loader=test_loader,
        checkpoint_dir=checkpoint_dir,
        device=device,
        epochs=epochs,
        samples_per_class=samples_per_class,
        should_train_from_scratch=should_train_from_scratch,
        reg_weight=reg_weight,
        transfer_learning_model_size=transfer_learning_model_size
    )


def print_config(
    device, model, optimizer, scheduler, epochs, loss_name, regularization_weight
):
    print("\n--- Experiment Configuration ---")
    print(f"Device:        {device}")
    print(f"Model:         {type(model).__name__}")
    print(f"Epochs:        {str(epochs)}")
    print(f"Optimizer:     {optimizer}")
    print(f"Scheduler:     {scheduler.state_dict()}")
    print(f"Criterion:     {loss_name}")
    print(f"Regularization Weight:     {str(regularization_weight)}")
    print("--------------------------------\n")


if __name__ == "__main__":
    # Create parser
    parser = argparse.ArgumentParser()

    # Add argument
    parser.add_argument("--loss_name", default="CE", type=str, help="loss name")
    parser.add_argument(
        "--reg_weight", default=None, type=float, help="regularization weight"
    )
    parser.add_argument(
        "--target_dataset_name", default=None, type=str, help="dataset name"
    )
    parser.add_argument(
        "--train_type", default="full_train", type=str, help="transfer / full_train"
    )
    parser.add_argument(
        "--samples_per_class", default=0, type=int, help="transfer / full train"
    )
    parser.add_argument("--epochs", default=0, type=int, help="number of epochs to run")
    parser.add_argument(
        "--is_hyperparam_tuning",
        default=0,
        type=int,
        help="is the run meant for tuning hyperparams",
    )
    parser.add_argument(
        "--should_train_from_scratch",
        default=0,
        type=int,
        help="should transfer learning train from scratch",
    )
    parser.add_argument(
        "--checkpoint_dir", default="", type=str, help="check point dir"
    )
    parser.add_argument(
        "--full_train_set",
        default=0,
        type=int,
        help="If True, use entire dataset for training and skip validation split.",
    )
    parser.add_argument(
        "--transfer_learning_model_size",
        default=None,
        type=int,
        help="ResNet model size for transfer learning (18 or 50) when training from scratch.",
    )

    # Parse arguments
    args = parser.parse_args()

    transfer_learning_model_size = args.transfer_learning_model_size
    epochs = args.epochs
    checkpoint_dir = CHECK_POINT_DIR
    regularization_weight = args.reg_weight
    use_full_train_set = bool(args.full_train_set)
    train_type = args.train_type

    # Access the variable
    print(
        "Using loss: " + args.loss_name + " reg_weight: " + str(regularization_weight)
    )
    match args.loss_name:
        case "CE":
            loss_name = "Cross_Entropy"
            criterion = nn.CrossEntropyLoss(label_smoothing=0.1)
        case "Cosine":
            loss_name = "CE_With_Cosine_Similarity"
            criterion = CECosineReg(regularization_weight)
        case "VICReg":
            loss_name = "CE_With_VICReg"
            criterion = CEVICReg(regularization_weight)
        case "SIGReg":
            loss_name = "CE_With_SIGReg"
            criterion = CESIGReg(regularization_weight)
        case _:
            raise ValueError(f"Invalid Loss Name: {args.loss_name}")

    if train_type == "full_train":
        batch_size = 128
        num_workers = 4

        train_loader, val_loader, test_loader, full_train_dataset, test_dataset = (
            get_imagenet_dataloaders(
                batch_size=batch_size,
                num_workers=num_workers,
                use_full_train_set=use_full_train_set,
            )
        )

        full_train_dataset.view_images(10, loader=train_loader)
        # Check if the class-to-index mappings are identical
        train_map = full_train_dataset.class_to_idx
        val_map = test_dataset.class_to_idx

        maps_match = train_map == val_map
        print(f"Do the mappings match? {maps_match}")

        if not maps_match:
            # Find the first mismatch
            for folder in train_map:
                if train_map[folder] != val_map.get(folder):
                    print(
                        f"Mismatch at {folder}: Train={train_map[folder]}, Val={val_map.get(folder)}"
                    )
                    break

        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model = ResNet(num_classes=100, model_size=50).to(device)
        augmentation_pipe = get_augmentation_pipeline()
        if epochs is None:
            epochs = 60

        optimizer = torch.optim.SGD(
            model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4
        )

        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)

        epochs = epochs
        print_config(
            device,
            model,
            optimizer,
            scheduler,
            epochs,
            loss_name,
            regularization_weight,
        )
        train_and_evaluate_cnn(
            model,
            device,
            loss_criterion=criterion,
            train_loader=train_loader,
            val_loader=val_loader,
            test_loader=test_loader,
            optimizer=optimizer,
            scheduler=scheduler,
            loss_name=loss_name,
            num_classes=model.num_classes,
            epochs=epochs,
            augmentation_pipeline=augmentation_pipe,
            checkpoint_dir=checkpoint_dir,
            is_hyperparam_tuning=args.is_hyperparam_tuning,
            reg_weight=regularization_weight,
        )
    else:
        if epochs is None:
            epochs = 20
        execute_transfer_learning(
            dataset_name=args.target_dataset_name,
            loss_name=loss_name,
            checkpoint_dir=checkpoint_dir,
            should_train_from_scratch=args.should_train_from_scratch,
            samples_per_class=args.samples_per_class,
            epochs=epochs,
            reg_weight=regularization_weight,
            use_full_train_set=use_full_train_set,
            transfer_learning_model_size=transfer_learning_model_size
        )
